with(wind.pred, lines(wind, wind3, col = 'blue', lwd = 2))
## Regressão ponimial de grau 6
energy6 <- lm(energy ~ poly(wind, 6), data = eolica)
wind.pred$wind6 <- predict(energy6, newdata = wind.pred)
with(wind.pred, lines(wind, wind6, col = 'red', lwd = 2))
## Loess
energyloess <- loess(energy~wind, data = eolica)
wind.pred$windloess <- predict(energyloess, newdata = wind.pred)
with(wind.pred, lines(wind, windloess, col = '#008000', lwd = 2))
## Splines
library(splines)
energyspline <- lm(energy~bs(wind), data = eolica)
wind.pred$windspline <- predict(energyspline, newdata = wind.pred)
with(wind.pred, lines(wind, windspline, col = '#4B0082', lwd = 2))
## Segmentada
fit <- lm(energy ~ wind, data=eolica)
segmented.fit <- segmented(fit, seg.Z = ~wind, npsi = 2)
plot(segmented.fit, add=T, col = '#D2691E', lwd = 2)
#----------------------------------------------------------------------
library(faraway)
dados <- wbca
View(dados)
## Verificando a quantidade de tumores
## de cada tipo
table(dados$Class)
prop.table(table(dados$Class))
## Vamos redefinir os níveis da variável classe de
## forma a modelar a probabilidade de tumor maligno:
dados$Class <- ifelse(dados$Class == 0, 1, 0)
table(dados$Class)
library(ggplot2)
library(gridExtra)
bp <- function(covariavel, xlab){
ggplot(dados,
aes(x=factor(Class),
y=covariavel,
color=factor(Class))) +
geom_boxplot()+
guides(color=FALSE)+
xlab(xlab)+
ylab('') +
theme_light()
}
g1 <- bp(dados[,2],names(dados[2]))
g2 <- bp(dados[,3],names(dados[3]))
g3 <- bp(dados[,4],names(dados[4]))
g4 <- bp(dados[,5],names(dados[5]))
g5 <- bp(dados[,6],names(dados[6]))
g6 <- bp(dados[,7],names(dados[7]))
g7 <- bp(dados[,8],names(dados[8]))
g8 <- bp(dados[,9],names(dados[9]))
g9 <- bp(dados[,10],names(dados[10]))
grid.arrange(g1, g2, g3,
g4, g5, g6,
g7, g8, g9,
ncol=3, nrow=3)
logit <- glm(Class ~ .,
family=binomial(link='logit'),
data = dados)
probit <- glm(Class ~ .,
family=binomial(link = 'probit'),
data = dados)
cloglog <- glm(Class ~ .,
family=binomial(link='cloglog'),
data = dados)
cauchit <- glm(Class ~ .,
family=binomial(link='cauchit'),
data = dados)
selec <-
data.frame(ajuste=c('logito', 'probito', 'cloglog', 'cauchy'),
aic=c(AIC(logit), AIC(probit),
AIC(cloglog), AIC(cauchit)),
logLik=c(logLik(logit),logLik(probit),
logLik(cloglog),logLik(cauchit)))
selec
# Análise do modelo ajustado selecionado
summary(probit)
# Reajuste do Modelo
probit2 <- step(probit, direction = "both")
summary(probit2)
# Comparando os modelos
anova(probit, probit2, test = 'Chisq')
library(statmod)
par(mfrow=c(1,2))
residuos <- qresiduals(probit)
plot(residuos)
qqnorm(residuos)
qqline(residuos, col = 2)
# Predição
perfis <- data.frame(Adhes = c(6,  3),
BNucl = c(9,  1),
Chrom = c(3,  7),
Mitos = c(9,  1),
NNucl = c(8,  3),
Thick = c(2,  4),
UShap = c(6,  5)
)
predict(probit2,
interval = 'prediction',
newdata = perfis,
type = 'response')
library(faraway)
dados <- wbca
View(dados)
## Verificando a quantidade de tumores
## de cada tipo
table(dados$Class)
prop.table(table(dados$Class))
## Vamos redefinir os níveis da variável classe de
## forma a modelar a probabilidade de tumor maligno:
dados$Class <- ifelse(dados$Class == 0, 1, 0)
table(dados$Class)
library(ggplot2)
library(gridExtra)
bp <- function(covariavel, xlab){
ggplot(dados,
aes(x=factor(Class),
y=covariavel,
color=factor(Class))) +
geom_boxplot()+
guides(color=FALSE)+
xlab(xlab)+
ylab('') +
theme_light()
}
g1 <- bp(dados[,2],names(dados[2]))
g2 <- bp(dados[,3],names(dados[3]))
g3 <- bp(dados[,4],names(dados[4]))
g4 <- bp(dados[,5],names(dados[5]))
g5 <- bp(dados[,6],names(dados[6]))
g6 <- bp(dados[,7],names(dados[7]))
g7 <- bp(dados[,8],names(dados[8]))
g8 <- bp(dados[,9],names(dados[9]))
g9 <- bp(dados[,10],names(dados[10]))
grid.arrange(g1, g2, g3,
g4, g5, g6,
g7, g8, g9,
ncol=3, nrow=3)
logit <- glm(Class ~ .,
family=binomial(link='logit'),
data = dados)
probit <- glm(Class ~ .,
family=binomial(link = 'probit'),
data = dados)
cloglog <- glm(Class ~ .,
family=binomial(link='cloglog'),
data = dados)
cauchit <- glm(Class ~ .,
family=binomial(link='cauchit'),
data = dados)
logit
logit
selec <-
data.frame(ajuste=c('logito', 'probito', 'cloglog', 'cauchy'),
aic=c(AIC(logit), AIC(probit),
AIC(cloglog), AIC(cauchit)),
logLik=c(logLik(logit),logLik(probit),
logLik(cloglog),logLik(cauchit)))
selec
# Análise do modelo ajustado selecionado
summary(probit)
# Análise do modelo ajustado selecionado
summary(probit)
# Reajuste do Modelo
probit2 <- step(probit, direction = "both")
summary(probit2)
anova(probit, probit2, test = 'Chisq')
library(statmod)
par(mfrow=c(1,2))
residuos <- qresiduals(probit)
plot(residuos)
qqnorm(residuos)
qqline(residuos, col = 2)
hist(residuos)
# Predição
perfis <- data.frame(Adhes = c(6,  3),
BNucl = c(9,  1),
Chrom = c(3,  7),
Mitos = c(9,  1),
NNucl = c(8,  3),
Thick = c(2,  4),
UShap = c(6,  5)
)
predict(probit2,
interval = 'prediction',
newdata = perfis,
type = 'response')
ipardes  <- read.csv2('https://raw.githubusercontent.com/lineu96/glm/master/consulta.csv',
header = T, sep = ';', dec = ',')
View(ipardes)
library(psych)
pairs.panels(ipardes[ , 2:7],
method = "pearson",
hist.col = 2,
density = TRUE,
ellipses = FALSE,
pch = 20,
lwd = 0.01
)
## Transformando as variáveis explicativas
ipardes$lpibpc <- log(ipardes$pibpc)
ipardes$later  <- log(ipardes$ater)
ipardes$lgurb <- log(ipardes$gurb)
ipardes$lfrvei <- log(ipardes$frvei)
ipardes$lpop   <- log(ipardes$pop)
pairs.panels(ipardes[ , c(2,8:12)],
method = "pearson",
hist.col = 2,
density = TRUE,
ellipses = FALSE,
pch = 20,
lwd = 0.01
)
library(MASS)
pois <- glm(actt ~ pibpc + ater + gurb + frvei + pop,
data = ipardes, family = 'poisson')
bin_neg <- glm.nb(actt ~ pibpc + ater + gurb + frvei + pop,
data = ipardes)
pois2 <- glm(actt ~ lpibpc + later + lgurb + lfrvei + lpop,
data = ipardes, family = 'poisson')
bin_neg2 <- glm.nb(actt ~ lpibpc + later + lgurb + lfrvei + lpop,
data = ipardes)
ajuste <- c('Poisson', 'Binomial Negativa',
'Poisson 2', 'Binomial Negativa 2')
aic <- c(AIC(pois),
AIC(bin_neg),
AIC(pois2),
AIC(bin_neg2))
verossimilhanca <- c(logLik(pois),
logLik(bin_neg),
logLik(pois2),
logLik(bin_neg2))
data.frame(ajuste, aic, verossimilhanca)
ajuste <- c('Poisson', 'Binomial Negativa',
'Poisson 2', 'Binomial Negativa 2')
aic <- c(AIC(pois),
AIC(bin_neg),
AIC(pois2),
AIC(bin_neg2))
verossimilhanca <- c(logLik(pois),
logLik(bin_neg),
logLik(pois2),
logLik(bin_neg2))
data.frame(ajuste, aic, verossimilhanca)
summary(bin_neg2)
# Reajustando o modelo
bin_neg2_step <- step(bin_neg2, direction = "both")
summary(bin_neg2_step)
summary(bin_neg2_step)
anova(bin_neg2, bin_neg2_step, test = 'Chisq')
library(statmod)
par(mfrow=c(1,2))
res <- qresiduals(bin_neg2_step)
plot(res)
residuos <- qresiduals(bin_neg2_step)
qqnorm(residuos)
qqline(residuos, col = 2)
perfis <- data.frame(lpibpc =  log(c(6500, 13000, 16000)),
lgurb =  log(c(10, 75, 84)),
lfrvei =  log(c(400,  3500,  7000)),
lpop =  log(c(1500, 9000, 17000)))
perfis
predict(bin_neg2_step,
interval = 'prediction',
newdata = perfis,
type = 'response')
r=mean(c(0,0,1.03,8.91,6.94,0,9.5))
r
mean(p1,p2,p3,r)
p1=0
p2=7.8
p3=9.3
p4=0
r=mean(c(0,0,1.03,8.91,6.94,0,9.5))
mean(p1,p2,p3,r)
mean(c(p1,p2,p3,r))
p1=10
p2=7.8
p3=9.3
p4=0
r=mean(c(0,0,1.03,8.91,6.94,0,9.5))
mean(c(p1,p2,p3,r))
p1=8
p2=7.8
p3=9.3
p4=0
r=mean(c(0,0,1.03,8.91,6.94,0,9.5))
mean(c(p1,p2,p3,r))
p1=7
p2=7.8
p3=9.3
p4=0
r=mean(c(0,0,1.03,8.91,6.94,0,9.5))
mean(c(p1,p2,p3,r))
p1=7.1
p2=7.8
p3=9.3
p4=0
r=mean(c(0,0,1.03,8.91,6.94,0,9.5))
mean(c(p1,p2,p3,r))
p1=7.2
p2=7.8
p3=9.3
p4=0
r=mean(c(0,0,1.03,8.91,6.94,0,9.5))
mean(c(p1,p2,p3,r))
p1=7.15
p2=7.8
p3=9.3
p4=0
r=mean(c(0,0,1.03,8.91,6.94,0,9.5))
mean(c(p1,p2,p3,r))
p1=7.13
p2=7.8
p3=9.3
p4=0
r=mean(c(0,0,1.03,8.91,6.94,0,9.5))
mean(c(p1,p2,p3,r))
p1=7.14
p2=7.8
p3=9.3
p4=0
r=mean(c(0,0,1.03,8.91,6.94,0,9.5))
mean(c(p1,p2,p3,r))
71*3
mean(c(p1,p2,p3,r))
p1=10
p2=7.8
p3=9.3
p4=0
r=mean(c(0,0,1.03,8.91,6.94,0,9.5))
mean(c(p1,p2,p3,r))
4500 + (0.52*4500)
4500 + (0.52*4500) + 1000
6000+2000
4556.92 + 1000 + 1594.922
4556.92 + 1000 + 2369.598
mean(c(4700,
5300,
6000,
7300,
7400))
23-5
4556.92*0.52
4556.92*0.30
4556.92*0.35
4556.92 + 1000 + 1594.922
4556.92 + 1000 + 2369.598
mean(c(4700,
5300,
6000,
7300,
7400))
25/65
c(25,18,22)/65
round(c(25,18,22)/65,2)
round(c(49,15,4)/68,2)
inicial = 137304
rendimento = 0.009
mes1 <- inicial + (inicial*rendimento)
mes1
mes1-inicial
inicial = 137304
rendimento = 0.009
mes1 <- inicial + (inicial*rendimento)
rendimento_mensal <- c(mes1)
meses=12*20
for (i in 1:meses) {
rendimento_mensal[i+1] <-
rendimento_mensal[i]+
(rendimento_mensal[i]*rendimento)
}
df <- data.frame(mes = 1:length(rendimento_mensal),
valor = rendimento_mensal)
df$mensal = c(0,diff(rendimento_mensal))
View(df)
20*12
28+20
exp( 1.454 )
exp( 1.17 +1.454 )
beta0=1.17
beta3=1.454
round(exp(beta0+beta3), 3)
22*50
22*60
22*100
22*200
22*250
22*210
22*220
22*225
22*230
(137953.82 * 230)/50
(137953.82 * 100)/50
50*22
(50*22)/137953.82
137953.82*0.008
137953.82*0.0079
inicial = 137953.82
rendimento = 0.0079
mes1 <- inicial + (inicial*rendimento)
mes1
137953.82 + 1100
inicial = 137953.82
rendimento = 0.0079
mes1 <- inicial + (inicial*rendimento)
rendimento_mensal <- c(mes1)
rendimento_mensal
meses=12*20
for (i in 1:meses) {
rendimento_mensal[i+1] <-
rendimento_mensal[i]+
(rendimento_mensal[i]*rendimento)
}
df <- data.frame(mes = 1:length(rendimento_mensal),
valor = rendimento_mensal)
df$mensal = c(0,diff(rendimento_mensal))
View(df)
10*1
10*12
12*20
inicial = 137953.82
rendimento = 0.0079
mes1 <- inicial + (inicial*rendimento)
rendimento_mensal <- c(mes1)
meses=12*30
for (i in 1:meses) {
rendimento_mensal[i+1] <-
rendimento_mensal[i]+
(rendimento_mensal[i]*rendimento)
}
df <- data.frame(mes = 1:length(rendimento_mensal),
valor = rendimento_mensal)
df$mensal = c(0,diff(rendimento_mensal))
View(df)
283/12
(283/12)+28
2024-1996
1000-387.65
1100-387.65
1080/30
36/12
inicial = 139353.82
rendimento = 0.0079
mes1 <- inicial + (inicial*rendimento)
rendimento_mensal <- c(mes1)
mes1
inicial = 139353.82
rendimento = 0.0079
mes1 <- inicial + (inicial*rendimento)
mes1
inicial*rendimento
inicial = 139353.82
rendimento = 0.0079
mes1 <- inicial + (inicial*rendimento)
rendimento_mensal <- c(mes1)
meses=12*30
for (i in 1:meses) {
rendimento_mensal[i+1] <-
rendimento_mensal[i]+
(rendimento_mensal[i]*rendimento)
}
df <- data.frame(mes = 1:length(rendimento_mensal),
valor = rendimento_mensal)
df$mensal = c(0,diff(rendimento_mensal))
View(df)
282/12
23.5+28
dbinom(1, size = 1, prob = 0.7)
rbinom(1, size = 1, prob = 0.7)
rbinom(10, size = 1, prob = 0.7)
bateria <- rbinom(10, size = 1, prob = 0.7)
sum(bateria)
sum(bateria)/10
bateria <- rbinom(10, size = 1, prob = 0.7)
sucesso <- sum(bateria)/10
sucesso
fracasso <- 1-sucesso
fracasso
data.frame(sucesso = sucesso,
fracasso = fracasso)
runif(1, min=-1, max=1)
runif(10, min=-1, max=1)
rnunif(100,-10,10)
runif(100,-10,10)
round(runif(100,-10,10))
x <- round(runif(100,-10,10))
table(x)
prop.table(table(x))
probs <- prop.table(table(x))
sample(-10:10, size = 1, replace = T, prob = probs)
sample(-10:10, size = 100, replace = T, prob = probs)
x2 <- sample(-10:10, size = 100, replace = T, prob = probs)
prop.table(table(x2))
data.frame(probs,
prop.table(table(x2)))
prop.table(table(x2))
probs2 <- prop.table(table(x2))
data.frame(probs,
probs2)
probs
probs2
sample(1, 70, replace = F)
sample(1, 70, replace = T)
sample(1:70, 10, replace = F)
setwd("~/CE009CE24")
rmarkdown::render_site()
rmarkdown::render_site()
rmarkdown::render_site()
setwd("~/CE009CS24")
rmarkdown::render_site()
rmarkdown::render_site()
